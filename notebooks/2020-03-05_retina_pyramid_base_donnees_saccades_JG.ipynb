{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overcomplete retinal pyramid\n",
    "## 1. Libraries & initialising parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-06T14:28:12+01:00\n",
      "\n",
      "CPython 3.7.0\n",
      "IPython 6.5.0\n",
      "\n",
      "numpy 1.15.1\n",
      "torch 1.4.0\n",
      "POLO not installed\n",
      "\n",
      "compiler   : MSC v.1912 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : DESKTOP-7F3QJKF\n",
      "Git hash   : 92bf03da8923a3555b179541349a4df41d924868\n",
      "Git repo   : https://github.com/bicv/POLO.git\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,torch,POLO  -r -g -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode= 'bilinear'\n",
    "width = 32\n",
    "r_min = width / 8 #width/16 \n",
    "r_max = width / 2 #7 * width/16\n",
    "#base_levels = 1.61803\n",
    "base_levels = 2\n",
    "n_sublevel = 4 #cette fois on en met 4\n",
    "n_azimuth = 2 #var 2->24\n",
    "n_theta = 3 #var 2->24\n",
    "n_phase = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image after the ocular saccade (mask) #TODO names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imread' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-100cca05d164>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/i05june05_static_street_boston_p1010764.jpeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimg_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_orig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m162\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sliding gaze to the right by moving image to the left\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sliding gaze to the top by moving image to the bottom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imread' is not defined"
     ]
    }
   ],
   "source": [
    "img_orig = imread('../data/i05june05_static_street_boston_p1010764.jpeg')\n",
    "ds = 1\n",
    "if ds>1: img_orig = img_orig[::ds, ::ds]\n",
    "img_orig = np.roll(img_orig, -162//ds, axis=1) # sliding gaze to the right by moving image to the left\n",
    "img_orig = np.roll(img_orig, 32//ds, axis=0) # sliding gaze to the top by moving image to the bottom\n",
    "from SLIP import Image\n",
    "N_X, N_Y = img_orig.shape\n",
    "pe = {'N_X': N_X, 'N_Y': N_Y, 'do_mask': True}\n",
    "\n",
    "im = Image(pe)\n",
    "img_orig -= img_orig.mean()\n",
    "img_orig *= im.mask\n",
    "img_tens = torch.Tensor(img_orig[None, None, ...])\n",
    "print('Tensor shape=', img_tens.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "ax.imshow(img_orig, cmap='gray')\n",
    "ax.plot([img_orig.shape[1]/2], [img_orig.shape[0]/2], 'r+', ms=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. using torch to build up a Laplacian pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "img_down = img_tens\n",
    "n_levels = 0\n",
    "while max(img_down.shape[-2:]) > width :\n",
    "    n_levels += 1\n",
    "    print('Tensor shape=', img_down.shape, ', n_levels=', n_levels)\n",
    "    #print(np.log(img_down.shape[-2:])/np.log(base_levels)-np.log(width)/np.log(base_levels))\n",
    "    img_down = interpolate(img_down, scale_factor=1/base_levels, mode=mode)\n",
    "n_levels += 1\n",
    "print('Top tensor shape=', img_down.shape, ', Final n_levels=', n_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cropped pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_pyramid(img_tens, width=width, base_levels=base_levels, verbose=False):\n",
    "    \n",
    "    N_batch, _, N_X, N_Y = img_tens.shape\n",
    "    n_levels = int(np.log(np.max((N_X, N_Y))/width)/np.log(base_levels)) + 1\n",
    "    \n",
    "    img_crop = torch.zeros((N_batch, n_levels, width, width))\n",
    "\n",
    "    img_down = img_tens.clone()\n",
    "    for i_level in range(n_levels-1):\n",
    "        img_residual = img_down.clone()\n",
    "        img_down = interpolate(img_down, scale_factor=1/base_levels, mode=mode)\n",
    "        img_residual -= interpolate(img_down, size=img_residual.shape[-2:], mode=mode)\n",
    "\n",
    "        if verbose: print('Tensor shape=', img_down.shape, ', shape=', img_residual.shape)\n",
    "        h_res, w_res = img_residual.shape[-2:]\n",
    "\n",
    "        img_crop[:, i_level, :, :] = img_residual[:, 0, \n",
    "                            (h_res//2-width//2):(h_res//2+width//2), \n",
    "                            (w_res//2-width//2):(w_res//2+width//2)]\n",
    "\n",
    "    h_res, w_res = img_down.shape[-2:]\n",
    "    img_crop[:, n_levels-1, \n",
    "             (width//2-h_res//2):(width//2+h_res//2), \n",
    "             (width//2-w_res//2):(width//2+w_res//2)] = img_down[:, 0, :, :]\n",
    "    #if verbose: print('Top tensor shape=', img_down.shape, ', Final n_levels=', n_levels)\n",
    "    return img_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating a set of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LogGabor import LogGabor\n",
    "pe = {'N_X': width, 'N_Y': width, 'do_mask': False, 'base_levels':\n",
    "          base_levels, 'n_theta': 24, 'B_sf': 0.6, 'B_theta': np.pi/12 ,\n",
    "      'use_cache': True, 'figpath': 'results', 'edgefigpath':\n",
    "          'results/edges', 'matpath': 'cache_dir', 'edgematpath':\n",
    "          'cache_dir/edges', 'datapath': 'database/', 'ext': '.pdf', 'figsize':\n",
    "          14.0, 'formats': ['pdf', 'png', 'jpg'], 'dpi': 450, 'verbose': 0}\n",
    "lg = LogGabor(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_filter(azimuth, theta, phase, sf_0=.25, radius=width/4):\n",
    "\n",
    "    x, y = lg.pe.N_X//2, lg.pe.N_Y//2 # center\n",
    "    x += radius * np.cos(azimuth)\n",
    "    y += radius * np.sin(azimuth)\n",
    "    \n",
    "    return lg.normalize(lg.invert(\n",
    "        lg.loggabor(x, y, sf_0=sf_0, B_sf=lg.pe.B_sf, theta=theta, B_theta=lg.pe.B_theta) * np.exp(-1j * phase)))\n",
    "\n",
    "K = local_filter(azimuth=0, theta=0, phase=0, radius=width/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K(width=width, n_sublevel = n_sublevel, n_azimuth = n_azimuth, n_theta = n_theta, \n",
    "          n_phase = n_phase, r_min = width/6, r_max = width/3, log_density_ratio = 2, verbose=False):\n",
    "    K = np.zeros((width, width, n_sublevel, n_azimuth, n_theta, n_phase))\n",
    "    for i_sublevel in range(n_sublevel):\n",
    "        \n",
    "        b = np.log(log_density_ratio)  / (r_max - r_min)\n",
    "        a = (r_max - r_min) / (np.exp (b * (r_max - r_min)) - 1)\n",
    "        c = r_min - a\n",
    "        r_ref = r_min + i_sublevel * (r_max - r_min) / n_sublevel\n",
    "        r_prim =  a * np.exp(b * (r_ref - r_min)) + c\n",
    "        radius =  r_prim\n",
    "        d_r_prim = a * b * np.exp(b * (r_ref - r_min))\n",
    "        p_ref = 4 * width / 32 \n",
    "        p_loc = p_ref * d_r_prim\n",
    "        sf_0 = 1 / p_loc\n",
    "        if verbose: print('r_ref', r_ref)\n",
    "        if verbose: print('i_sublevel, sf_0, radius', i_sublevel, sf_0, radius)\n",
    "        for i_azimuth in range(n_azimuth):\n",
    "            for i_theta in range(n_theta):\n",
    "                for i_phase in range(n_phase):\n",
    "                    azimuth = (i_azimuth+i_sublevel/2)*2*np.pi/n_azimuth\n",
    "                    theta = i_theta*np.pi/n_theta + azimuth\n",
    "                    phase = i_phase*np.pi/n_phase\n",
    "                    K[..., i_sublevel, i_azimuth, i_theta, i_phase] = local_filter(azimuth=azimuth, \n",
    "                                                                                   theta=theta, \n",
    "                                                                                   phase=phase, \n",
    "                                                                                   sf_0=sf_0, \n",
    "                                                                                   radius=radius)\n",
    "    K = torch.Tensor(K)\n",
    "\n",
    "    if verbose: print('K shape=', K.shape)\n",
    "    if verbose: print('K min max=', K.min(), K.max())\n",
    "\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying the filters OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inverse pyramid from the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pyramid(out, K_inv, N_X=N_X, N_Y=N_Y, \n",
    "                    n_sublevel=n_sublevel, n_azimuth = n_azimuth, n_theta = n_theta, n_phase=n_phase,\n",
    "                    base_levels=base_levels, verbose=False):\n",
    "    N_batch = out.shape[0]\n",
    "    # width =  K_inv.shape[0]\n",
    "    #n_levels = int(np.log(np.max((N_X, N_Y))/width)/np.log(base_levels)) + 1\n",
    "    #n_sublevel, n_azimuth, n_theta, n_phase = K_inv.shape[2:]\n",
    "    #print('n_levels =', n_levels)\n",
    "    out__ = out.reshape((N_batch, n_levels, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "    #K_ = K.reshape((width**2, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "    #K_inv = torch.pinverse(K_)\n",
    "    img_crop_rec =  torch.tensordot(out__, K_inv,  dims=1).reshape((N_batch, n_levels, width, width))\n",
    "\n",
    "    img_rec = img_crop_rec[:, -1, :, :].unsqueeze(1)\n",
    "    for i_level in range(n_levels-1)[::-1]: # from the top to the bottom of the pyramid\n",
    "        img_rec = interpolate(img_rec, scale_factor=base_levels, mode=mode)\n",
    "        h_res, w_res = img_rec.shape[-2:]\n",
    "        img_rec[:, 0, (h_res//2-width//2):(h_res//2+width//2), (w_res//2-width//2):(w_res//2+width//2)] += img_crop_rec[:, i_level, :, :]\n",
    "    img_rec = img_rec[:, :, (h_res//2-N_X//2):(h_res//2+N_X//2), (w_res//2-N_Y//2):(w_res//2+N_Y//2)]\n",
    "\n",
    "    return img_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Retinal transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyr_transfo_ret(img_orig, K_azym_thet, n_azimuth = n_azimuth, n_theta = n_theta):\n",
    "    img_crop = cropped_pyramid(torch.Tensor(img_orig[None, None, ...]), verbose=False)\n",
    "    out = torch.tensordot(img_crop, K_azym_thet,  dims=2)\n",
    "    K_ = K_azym_thet.reshape((width**2, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "    K_azym_thet_inv = torch.pinverse(K_)\n",
    "    img_rec = inverse_pyramid(out, K_azym_thet_inv, n_azimuth = n_azimuth, n_theta = n_theta)\n",
    "    return img_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
