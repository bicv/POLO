{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='nearest'\n",
    "width = 32\n",
    "base_levels = 1.61803\n",
    "base_levels = 2\n",
    "n_sublevel = 2\n",
    "n_azimuth = 18\n",
    "n_theta = 8\n",
    "n_phase = 2\n",
    "\n",
    "N_batch = 4\n",
    "pattern = 'i05june05_static_street_boston_*.jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14T11:08:27+01:00\n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.12.0\n",
      "\n",
      "numpy 1.18.1\n",
      "torch 1.4.0\n",
      "POLO not installed\n",
      "\n",
      "compiler   : Clang 11.0.0 (clang-1100.0.33.16)\n",
      "system     : Darwin\n",
      "release    : 19.3.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 36\n",
      "interpreter: 64bit\n",
      "host name  : fortytwo\n",
      "Git hash   : 9658e97b58cf7bd223065035141726ef1f65e7e3\n",
      "Git repo   : https://github.com/bicv/POLO/\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -i -h -m -v -p numpy,torch,POLO  -r -g -b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800px-Fox_Hunt_1893_Winslow_Homer.jpg\n",
      "homer.jpg\n",
      "\u001b[31mi05june05_static_street_boston_p1010764.jpeg\u001b[m\u001b[m*\n",
      "i05june05_static_street_boston_p1010764.npy\n",
      "\u001b[31mi05june05_static_street_boston_p1010785.jpeg\u001b[m\u001b[m*\n",
      "\u001b[31mi05june05_static_street_boston_p1010800.jpeg\u001b[m\u001b[m*\n",
      "\u001b[31mi05june05_static_street_boston_p1010806.jpeg\u001b[m\u001b[m*\n",
      "\u001b[31mi05june05_static_street_boston_p1010808.jpeg\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "%ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLIP import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape= torch.Size([1, 1, 192, 256])\n"
     ]
    }
   ],
   "source": [
    "img_orig = imread('../data/i05june05_static_street_boston_p1010764.jpeg')\n",
    "ds = 4\n",
    "if ds>1: img_orig = img_orig[::ds, ::ds]\n",
    "img_orig = np.roll(img_orig, -162//ds, axis=1) # sliding gaze to the right by moving image to the left\n",
    "img_orig = np.roll(img_orig, 32//ds, axis=0) # sliding gaze to the top by moving image to the bottom\n",
    "from SLIP import Image\n",
    "N_X, N_Y = img_orig.shape\n",
    "pe = {'N_X': N_X, 'N_Y': N_Y, 'do_mask': True, 'do_whitening': True,\n",
    "       'white_n_learning': 0, 'white_N': 0.07, 'white_N_0': 0.0, 'white_f_0': 0.4, 'white_alpha': 1.4,\n",
    "      'white_steepness': 4.0}\n",
    "\n",
    "im = Image(pe)\n",
    "img_orig = im.whitening(img_orig) * im.mask\n",
    "img_tens = torch.Tensor(img_orig[None, None, ...])\n",
    "print('Tensor shape=', img_tens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# using torch to build up a Gaussian pyramid\n",
    "\n",
    "https://pytorch.org/docs/master/nn.functional.html#torch.nn.functional.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recursively down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "from torch.nn.functional import max_pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.2 µs ± 1.44 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "interpolate(img_tens, scale_factor=1/2, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 µs ± 5.52 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "max_pool2d(img_tens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape= torch.Size([1, 1, 192, 256]) , n_levels= 1\n",
      "Tensor shape= torch.Size([1, 1, 96, 128]) , n_levels= 2\n",
      "Tensor shape= torch.Size([1, 1, 48, 64]) , n_levels= 3\n",
      "Top tensor shape= torch.Size([1, 1, 24, 32]) , Final n_levels= 4\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "img_down = img_tens\n",
    "n_levels = 0\n",
    "while max(img_down.shape[-2:]) > width :\n",
    "    n_levels += 1\n",
    "    print('Tensor shape=', img_down.shape, ', n_levels=', n_levels)\n",
    "    img_down = interpolate(img_down, scale_factor=1/base_levels, mode=mode)\n",
    "n_levels += 1\n",
    "print('Top tensor shape=', img_down.shape, ', Final n_levels=', n_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying on the central crop of $32\\times32$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_pyramid(img_tens, n_levels=n_levels, width=width, base_levels=base_levels, verbose=False):\n",
    "    N_batch = img_tens.shape[0]\n",
    "    img_crop = torch.zeros((N_batch, n_levels, width, width))\n",
    "\n",
    "    img_down = img_tens\n",
    "    for i_level in range(n_levels-1):\n",
    "        if verbose: print('Tensor shape=', img_down.shape, ', shape=', img_tens.shape)\n",
    "        h_res, w_res = img_down.shape[-2:]\n",
    "\n",
    "        img_crop[:, i_level, :, :] = img_down[:, 0, \n",
    "                            (h_res//2-width//2):(h_res//2+width//2), \n",
    "                            (w_res//2-width//2):(w_res//2+width//2)]\n",
    "        img_down = interpolate(img_down, scale_factor=1/base_levels, mode=mode)\n",
    "\n",
    "    h_res, w_res = img_down.shape[-2:]\n",
    "    img_crop[:, n_levels-1, \n",
    "             (width//2-h_res//2):(width//2+h_res//2), \n",
    "             (width//2-w_res//2):(width//2+w_res//2)] = img_down[:, 0, :, :]\n",
    "    return img_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a set of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lg shape= 32 32\n"
     ]
    }
   ],
   "source": [
    "from LogGabor import LogGabor\n",
    "pe = {'N_X': width, 'N_Y': width, 'do_mask': False, 'do_whitening': True,\n",
    "      'white_name_database': 'kodakdb', 'white_n_learning': 0, 'white_N':\n",
    "          0.07, 'white_N_0': 0.0, 'white_f_0': 0.4, 'white_alpha': 1.4,\n",
    "      'white_steepness': 4.0, 'white_recompute': False, 'base_levels':\n",
    "          base_levels, 'n_theta': 24, 'B_sf': 0.6, 'B_theta': np.pi/12 ,\n",
    "      'use_cache': True, 'figpath': 'results', 'edgefigpath':\n",
    "          'results/edges', 'matpath': 'cache_dir', 'edgematpath':\n",
    "          'cache_dir/edges', 'datapath': 'database/', 'ext': '.pdf', 'figsize':\n",
    "          14.0, 'formats': ['pdf', 'png', 'jpg'], 'dpi': 450, 'verbose': 0}\n",
    "lg = LogGabor(pe)\n",
    "print('lg shape=', lg.pe.N_X, lg.pe.N_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K shape= (32, 32)\n",
      "K min max= -0.4102999708906189 1.0\n"
     ]
    }
   ],
   "source": [
    "def local_filter(azimuth, theta, phase, sf_0=.25, radius=width/4):\n",
    "\n",
    "    x, y = lg.pe.N_X//2, lg.pe.N_Y//2 # center\n",
    "    x += radius * np.cos(azimuth)\n",
    "    y += radius * np.sin(azimuth)\n",
    "    \n",
    "    return lg.normalize(lg.invert(\n",
    "        lg.loggabor(x, y, sf_0=sf_0, B_sf=lg.pe.B_sf, theta=theta, B_theta=lg.pe.B_theta) * np.exp(-1j * phase)))\n",
    "\n",
    "K = local_filter(azimuth=0, theta=0, phase=0, radius=width/4)\n",
    "print('K shape=', K.shape)\n",
    "print('K min max=', K.min(), K.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_sublevel, sf_0, radius 0 0.25 8.0\n",
      "i_sublevel, sf_0, radius 1 0.3535533905932738 5.65685424949238\n",
      "K shape= torch.Size([32, 32, 2, 18, 8, 2])\n",
      "K min max= tensor(-1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def get_K(width=width, n_sublevel = n_sublevel, n_azimuth = n_azimuth, n_theta = n_theta, n_phase = n_phase, verbose=False):\n",
    "    K = np.zeros((width, width, n_sublevel, n_azimuth, n_theta, n_phase))\n",
    "    for i_sublevel in range(n_sublevel):\n",
    "        sf_0 = .25*(np.sqrt(2)**i_sublevel)\n",
    "        radius = width/4/(np.sqrt(2)**i_sublevel)\n",
    "        if verbose: print('i_sublevel, sf_0, radius', i_sublevel, sf_0, radius)\n",
    "        for i_azimuth in range(n_azimuth):\n",
    "            for i_theta in range(n_theta):\n",
    "                for i_phase in range(n_phase):\n",
    "                    K[..., i_sublevel, i_azimuth, i_theta, i_phase] = local_filter(azimuth=(i_azimuth+i_sublevel/2)*2*np.pi/n_azimuth, \n",
    "                                                                                   theta=i_theta*np.pi/n_theta, \n",
    "                                                                                   phase=i_phase*np.pi/n_phase, sf_0=sf_0, radius=radius)\n",
    "    K = torch.Tensor(K)\n",
    "\n",
    "    if verbose: print('K shape=', K.shape)\n",
    "    if verbose: print('K min max=', K.min(), K.max())\n",
    "\n",
    "    return K\n",
    "\n",
    "\n",
    "K = get_K(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_crop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-08009f96bc2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor shape='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_crop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_crop' is not defined"
     ]
    }
   ],
   "source": [
    "print('Tensor shape=', img_crop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "out = torch.tensordot(img_crop, K,  dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensordot(img_crop, K,  dims=2)\n",
    "print('Tensor shape=', out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer by layer from cropped central images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, n_levels, figsize=(20,20))\n",
    "for i_level, ax in enumerate(axs):\n",
    "    ax.imshow(img_crop.numpy()[0, i_level, ...], cmap='gray')\n",
    "    ax.plot([width/2], [width/2], 'r+', ms=16);\n",
    "print('Tensor shape=', img_crop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tensor shape=', K.shape)\n",
    "K_ = K.reshape((width**2, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "print('Tensor shape=', K_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tensor shape=', out.shape)\n",
    "out__ = out.reshape((1, n_levels, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "print('Tensor shape=', out__.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec =  torch.tensordot(out__, K_.T,  dims=1).reshape((1, n_levels, width, width))\n",
    "print('Tensor shape=', img_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, n_levels, figsize=(20,20))\n",
    "for i_level, ax in enumerate(axs):\n",
    "    ax.imshow(img_rec.numpy()[0, i_level, ...], cmap='gray')\n",
    "print('Tensor shape=', img_crop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inverse pyramid from the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pyramid(out, K, N_X=N_X, N_Y=N_Y, n_levels=n_levels, width=width, base_levels=base_levels, damp=2, verbose=False):\n",
    "    N_batch = out.shape[0]\n",
    "    n_sublevel, n_azimuth, n_theta, n_phase = K.shape[2:]\n",
    "    out__ = out.reshape((N_batch, n_levels, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "    K_ = K.reshape((width**2, n_sublevel*n_azimuth*n_theta*n_phase))\n",
    "    img_crop_rec =  torch.tensordot(out__, K_.T,  dims=1).reshape((N_batch, n_levels, width, width))\n",
    "\n",
    "    img_rec = img_crop_rec[:, -1, :, :].unsqueeze(1)\n",
    "    for i_level in range(n_levels-1)[::-1]: # from the top to the bottom of the pyramid\n",
    "        img_rec = interpolate(img_rec, scale_factor=base_levels, mode=mode) / damp\n",
    "        h_res, w_res = img_rec.shape[-2:]\n",
    "        img_rec[:, 0, (h_res//2-width//2):(h_res//2+width//2), (w_res//2-width//2):(w_res//2+width//2)] += img_crop_rec[:, i_level, :, :]\n",
    "    img_rec = img_rec[:, :, (h_res//2-N_X//2):(h_res//2+N_X//2), (w_res//2-N_Y//2):(w_res//2+N_Y//2)]\n",
    "\n",
    "    return img_rec\n",
    "\n",
    "img_rec = inverse_pyramid(out, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20,20))\n",
    "for ax, img in zip(axs, [img_tens, img_rec.detach()]):\n",
    "    ax.imshow(img[0, 0, :, :].numpy(), cmap='gray')\n",
    "    ax.plot([N_Y//2], [N_X//2], 'r+', ms=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizing the reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining a dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(K, N_batch, verbose=False)\n",
    "for batch_idx, (target, out) in enumerate(test_dataloader):\n",
    "    print(batch_idx, target.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec = inverse_pyramid(out, K, damp=2)\n",
    "print('img_rec.shape', img_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch in range(N_batch):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    for ax, img in zip(axs, [target[i_batch, 0, :, :], img_rec[i_batch, 0, :, :]]):\n",
    "        ax.imshow(img.numpy(), cmap='gray')\n",
    "        ax.plot([N_Y//2], [N_X//2], 'r+', ms=16);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = get_K(n_azimuth = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(K, N_batch, verbose=False)\n",
    "for batch_idx, (target, out) in enumerate(test_dataloader):\n",
    "    print(batch_idx, target.shape, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec = inverse_pyramid(out, K)\n",
    "print('img_rec.shape', img_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch in range(N_batch):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    for ax, img in zip(axs, [target[i_batch, 0, :, :], img_rec[i_batch, 0, :, :]]):\n",
    "        ax.imshow(img.numpy(), cmap='gray')\n",
    "        ax.plot([N_Y//2], [N_X//2], 'r+', ms=16);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimating running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "K = get_K()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch = 1024\n",
    "test_dataloader = get_dataloader(K, N_batch, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_dataloader = get_dataloader(K, N_batch, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "out = torch.tensordot(img_crop, K,  dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensordot(img_crop, K,  dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "img_rec = inverse_pyramid(out, K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
